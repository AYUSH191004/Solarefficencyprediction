{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f1d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from packaging import version\n",
    "import optuna\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b269f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  Load Data --------\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = train_df.drop(columns=['efficiency'])\n",
    "y_train = train_df['efficiency']\n",
    "X_test = test_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Feature Engineering with Robust Handling --------\n",
    "class SolarFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def _init_(self):\n",
    "        self.numeric_cols_ = ['voltage', 'current', 'irradiance', 'temperature', 'wind_speed', \n",
    "                              'soiling_ratio', 'module_temperature', 'panel_age', 'maintenance_count',\n",
    "                              'humidity', 'pressure', 'cloud_coverage']\n",
    "        self.imputer_ = SimpleImputer(strategy='median')\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X_numeric = X[self.numeric_cols_].copy()\n",
    "    \n",
    "        for col in self.numeric_cols_:\n",
    "            X_numeric[col] = pd.to_numeric(X_numeric[col], errors='coerce')\n",
    "            if X_numeric[col].isna().any():\n",
    "                print(f\"Warning: Non-numeric values or NaNs found in {col}, converted to NaN for imputation\")\n",
    "    \n",
    "        self.imputer_.fit(X_numeric)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "      \n",
    "        X_numeric = X[self.numeric_cols_].copy()\n",
    "        for col in self.numeric_cols_:\n",
    "            X_numeric[col] = pd.to_numeric(X_numeric[col], errors='coerce')\n",
    "        X[self.numeric_cols_] = self.imputer_.transform(X_numeric)\n",
    "        \n",
    "        # Optimized feature creation\n",
    "        X['power_output'] = X['voltage'] * X['current']\n",
    "        X['irradiance_temp_ratio'] = X['irradiance'] / (X['temperature'] + 1e-6)\n",
    "        X['efficiency_loss_due_to_soiling'] = X['soiling_ratio'] * X['irradiance']\n",
    "        X['temp_diff'] = X['module_temperature'] - X['temperature']\n",
    "        X['age_per_maintenance'] = X['panel_age'] / (X['maintenance_count'] + 1)\n",
    "        X['is_soiled'] = (X['soiling_ratio'] > 0.5).astype(int)\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -- Preprocessing Pipeline --------\n",
    "numeric_cols = ['voltage', 'current', 'irradiance', 'temperature', 'wind_speed', \n",
    "                'soiling_ratio', 'module_temperature', 'panel_age', 'maintenance_count',\n",
    "                'humidity', 'pressure', 'cloud_coverage', 'power_output', \n",
    "                'irradiance_temp_ratio', 'efficiency_loss_due_to_soiling', \n",
    "                'temp_diff', 'age_per_maintenance', 'is_soiled']\n",
    "categorical_cols = ['string_id', 'error_code', 'installation_type']\n",
    "\n",
    "if version.parse(sklearn._version_) >= version.parse(\"1.2\"):\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "else:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', ohe)\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_cols),\n",
    "    ('cat', cat_pipeline, categorical_cols)\n",
    "], sparse_threshold=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33ae52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18499aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply preprocessing\n",
    "fe = SolarFeatureEngineer()\n",
    "X_train_fe = fe.fit_transform(X_train)\n",
    "X_test_fe = fe.transform(X_test)\n",
    "\n",
    "top_feats = ['irradiance', 'temperature', 'soiling_ratio', 'module_temperature']\n",
    "if X_train_fe[top_feats].isna().any().any():\n",
    "    raise ValueError(\"NaN values found in top_feats after feature engineering\")\n",
    "\n",
    "X_train_processed = full_pipeline.fit_transform(X_train_fe)\n",
    "X_test_processed = full_pipeline.transform(X_test_fe)\n",
    "\n",
    "\n",
    "if hasattr(X_train_processed, 'toarray'):\n",
    "    X_train_processed = X_train_processed.toarray()\n",
    "    X_test_processed = X_test_processed.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26683ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Polynomial Features --------\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly_train = poly.fit_transform(X_train_fe[top_feats])\n",
    "X_poly_test = poly.transform(X_test_fe[top_feats])\n",
    "\n",
    "X_train_combined = np.hstack([X_train_processed, X_poly_train])\n",
    "X_test_combined = np.hstack([X_test_processed, X_poly_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --Efficient Feature Selection --------\n",
    "# Dynamically set max_features based on available features\n",
    "n_features = X_train_combined.shape[1]\n",
    "max_features = min(50, n_features)  # Ensure max_features <= n_features\n",
    "if max_features < 10:\n",
    "    print(f\"Warning: Only {n_features} features available, using all features\")\n",
    "    X_train_selected = X_train_combined\n",
    "    X_test_selected = X_test_combined\n",
    "else:\n",
    "    lgb_selector = LGBMRegressor(n_estimators=100, random_state=42, device=\"gpu\")\n",
    "    selector = SelectFromModel(lgb_selector, max_features=max_features)\n",
    "    selector.fit(X_train_combined, y_train)\n",
    "    X_train_selected = selector.transform(X_train_combined)\n",
    "    X_test_selected = selector.transform(X_test_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Optuna Hyperparameter Tuning --------\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'xgb_n_estimators': trial.suggest_int('xgb_n_estimators', 100, 500),  \n",
    "        'xgb_learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3, log=True),\n",
    "        'lgb_n_estimators': trial.suggest_int('lgb_n_estimators', 100, 500),\n",
    "        'lgb_learning_rate': trial.suggest_float('lgb_learning_rate', 0.01, 0.3, log=True),\n",
    "        'cat_iterations': trial.suggest_int('cat_iterations', 100, 500),\n",
    "        'cat_learning_rate': trial.suggest_float('cat_learning_rate', 0.01, 0.3, log=True),\n",
    "        'ridge_alpha': trial.suggest_float('ridge_alpha', 0.1, 10.0)\n",
    "    }\n",
    "    \n",
    "    model = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('xgb', XGBRegressor(n_estimators=params['xgb_n_estimators'], \n",
    "                                 learning_rate=params['xgb_learning_rate'], \n",
    "                                 random_state=42, device=\"cuda\")),\n",
    "            ('lgb', LGBMRegressor(n_estimators=params['lgb_n_estimators'], \n",
    "                                  learning_rate=params['lgb_learning_rate'], \n",
    "                                  random_state=42, device=\"gpu\")),\n",
    "            ('cat', CatBoostRegressor(iterations=params['cat_iterations'], \n",
    "                                      learning_rate=params['cat_learning_rate'], \n",
    "                                      task_type=\"GPU\", verbose=0, random_state=42))\n",
    "        ],\n",
    "        final_estimator=Ridge(alpha=params['ridge_alpha']),\n",
    "        passthrough=True,\n",
    "        n_jobs=1 \n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_selected, y_train)\n",
    "    preds = model.predict(X_train_selected)\n",
    "    rmse = np.sqrt(np.mean((y_train - preds) ** 2))\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4989500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final Model --------\n",
    "best_params = study.best_params\n",
    "final_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('xgb', XGBRegressor(n_estimators=best_params['xgb_n_estimators'], \n",
    "                             learning_rate=best_params['xgb_learning_rate'], \n",
    "                             random_state=42, device=\"cuda\")),\n",
    "        ('lgb', LGBMRegressor(n_estimators=best_params['lgb_n_estimators'], \n",
    "                              learning_rate=best_params['lgb_learning_rate'], \n",
    "                              random_state=42, device=\"gpu\")),\n",
    "        ('cat', CatBoostRegressor(iterations=best_params['cat_iterations'], \n",
    "                                  learning_rate=best_params['cat_learning_rate'], \n",
    "                                  task_type=\"GPU\", verbose=0, random_state=42))\n",
    "    ],\n",
    "    final_estimator=Ridge(alpha=best_params['ridge_alpha']),\n",
    "    passthrough=True,\n",
    "    n_jobs=1\n",
    ")\n",
    "final_model.fit(X_train_selected, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2039d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Predict and Save \n",
    "y_pred_test = final_model.predict(X_test_selected)\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'efficiency': y_pred_test\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29552060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Validate submission format\n",
    "if len(output_df) != 12000:\n",
    "    raise ValueError(f\"Submission file has {len(output_df)} rows, expected 12000\")\n",
    "if not output_df.columns.tolist() == ['id', 'efficiency']:\n",
    "    raise ValueError(\"Submission file must have columns ['id', 'efficiency']\")\n",
    "\n",
    "output_df.to_csv(\"gpu_optimized_predictions_v3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c29fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "joblib.dump(final_model, 'gpu_solar_efficiency_model_v3.pkl')\n",
    "print(\"GPU-optimized pipeline complete. Predictions saved to gpu_optimized_predictions_v3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
